/* Generated By:JavaCC: Do not edit this line. XQueryParser.java */
package net.sf.xpontus.plugins.lexer.xquery;

import net.sf.xpontus.plugins.lexer.LexerPluginIF;
import net.sf.xpontus.syntax.CharStream;
import net.sf.xpontus.syntax.IColorProvider;
import net.sf.xpontus.syntax.LexerInputStream;
import net.sf.xpontus.syntax.ParseException;
import net.sf.xpontus.syntax.Token;
import net.sf.xpontus.syntax.TokenMgrError;

import java.io.*;

import java.util.*;

import javax.swing.text.Segment;


public class XQueryParser implements LexerPluginIF, XQueryParserConstants {
    static private int[] jj_la1_0;
    static private int[] jj_la1_1;
    static private int[] jj_la1_2;

    static {
        jj_la1_0();
        jj_la1_1();
        jj_la1_2();
    }

    private List tokens = new ArrayList();
    public XQueryParserTokenManager token_source;
    public Token token;
    public Token jj_nt;
    private int jj_ntk;
    private int jj_gen;
    final private int[] jj_la1 = new int[0];
    private java.util.Vector jj_expentries = new java.util.Vector();
    private int[] jj_expentry;
    private int jj_kind = -1;
    private IColorProvider colorer = new XQueryColorProviderImpl();

    public XQueryParser() {
        this((LexerInputStream) null);
    }

    public XQueryParser(CharStream stream) {
        token_source = new XQueryParserTokenManager(stream);
        token = new Token();
        jj_ntk = -1;
        jj_gen = 0;

        for (int i = 0; i < 0; i++)
            jj_la1[i] = -1;
    }

    public XQueryParser(XQueryParserTokenManager tm) {
        token_source = tm;
        token = new Token();
        jj_ntk = -1;
        jj_gen = 0;

        for (int i = 0; i < 0; i++)
            jj_la1[i] = -1;
    }

    public void ReInit(Reader reader) {
        ReInit(new LexerInputStream(reader));
    }

    public int getLastTokenTypeOnLine(Segment text, int initialTokenType) {
        getTokens(text, initialTokenType, 0);

        return ((Token) tokens.get(tokens.size() - 1)).kind;
    }

    public List getTokens(Segment text, int initialTokenType, int startOffset) {
        tokens.clear();

        int state = DEFAULT;

        switch (initialTokenType) {
        case START_MULTILINE_COMMENT:
            state = IN_MULTILINE_COMMENT;

            break;

        case MULTILINE_COMMENT_CHAR:
            state = IN_MULTILINE_COMMENT;

            break;

        default:
            break;
        }

        try {
            Reader reader = new CharArrayReader(text.array, text.offset,
                    text.count);
            ReInit(new LexerInputStream(reader));
            this.token_source.SwitchTo(state);

            Token currentToken = null;

            while ((currentToken = getNextToken()).kind != XQueryParserConstants.EOF) {
                tokens.add(currentToken);
            }
        } catch (TokenMgrError err) {
            String mText = text.toString();

            int pos = this.token_source.input_stream.getColumn();

            String currentImage = this.token_source.input_stream.GetImage();

            mText = currentImage + mText.substring(pos, mText.length());

            tokens.add(new Token(mText, initialTokenType));
        }

        if (tokens.size() == 0) {
            tokens.add(new Token("", initialTokenType));
        }

        return tokens;
    }

    private static void jj_la1_0() {
        jj_la1_0 = new int[] {  };
    }

    private static void jj_la1_1() {
        jj_la1_1 = new int[] {  };
    }

    private static void jj_la1_2() {
        jj_la1_2 = new int[] {  };
    }

    public void ReInit(CharStream stream) {
        token_source.ReInit(stream);
        token = new Token();
        jj_ntk = -1;
        jj_gen = 0;

        for (int i = 0; i < 0; i++)
            jj_la1[i] = -1;
    }

    public void ReInit(XQueryParserTokenManager tm) {
        token_source = tm;
        token = new Token();
        jj_ntk = -1;
        jj_gen = 0;

        for (int i = 0; i < 0; i++)
            jj_la1[i] = -1;
    }

    final private Token jj_consume_token(int kind) throws ParseException {
        Token oldToken;

        if ((oldToken = token).next != null) {
            token = token.next;
        } else {
            token = token.next = token_source.getNextToken();
        }

        jj_ntk = -1;

        if (token.kind == kind) {
            jj_gen++;

            return token;
        }

        token = oldToken;
        jj_kind = kind;
        throw generateParseException();
    }

    final public Token getNextToken() {
        if (token.next != null) {
            token = token.next;
        } else {
            token = token.next = token_source.getNextToken();
        }

        jj_ntk = -1;
        jj_gen++;

        return token;
    }

    final public Token getToken(int index) {
        Token t = token;

        for (int i = 0; i < index; i++) {
            if (t.next != null) {
                t = t.next;
            } else {
                t = t.next = token_source.getNextToken();
            }
        }

        return t;
    }

    final private int jj_ntk() {
        if ((jj_nt = token.next) == null) {
            return (jj_ntk = (token.next = token_source.getNextToken()).kind);
        } else {
            return (jj_ntk = jj_nt.kind);
        }
    }

    public ParseException generateParseException() {
        jj_expentries.removeAllElements();

        boolean[] la1tokens = new boolean[90];

        for (int i = 0; i < 90; i++) {
            la1tokens[i] = false;
        }

        if (jj_kind >= 0) {
            la1tokens[jj_kind] = true;
            jj_kind = -1;
        }

        for (int i = 0; i < 0; i++) {
            if (jj_la1[i] == jj_gen) {
                for (int j = 0; j < 32; j++) {
                    if ((jj_la1_0[i] & (1 << j)) != 0) {
                        la1tokens[j] = true;
                    }

                    if ((jj_la1_1[i] & (1 << j)) != 0) {
                        la1tokens[32 + j] = true;
                    }

                    if ((jj_la1_2[i] & (1 << j)) != 0) {
                        la1tokens[64 + j] = true;
                    }
                }
            }
        }

        for (int i = 0; i < 90; i++) {
            if (la1tokens[i]) {
                jj_expentry = new int[1];
                jj_expentry[0] = i;
                jj_expentries.addElement(jj_expentry);
            }
        }

        int[][] exptokseq = new int[jj_expentries.size()][];

        for (int i = 0; i < jj_expentries.size(); i++) {
            exptokseq[i] = (int[]) jj_expentries.elementAt(i);
        }

        return new ParseException(token, exptokseq, tokenImage);
    }

    final public void enable_tracing() {
    }

    final public void disable_tracing() {
    }

    public String getMimeType() {
        return "text/xquery";
    }

    public String getName() {
        return "XQuery Lexer";
    }

    public String getDescription() {
        return "Syntax support for XQuery files";
    }

    public String getLexerClassName() {
        return getClass().getName();
    }

    public boolean hasCodeCompletion() {
        return false;
    }

    public String getCodeCompletionClassName() {
        return null;
    }

    public IColorProvider getColorer() {
        return colorer;
    }

    public String[] getSupportedExtensions() {
        return new String[] { "xquery" };
    }
}
